## Corrigindo o roteamento do Supervisor com Tools (RoutingTool)

### Problema retomado

* No vídeo anterior, o Supervisor já usava IA para escolher o próximo nó do grafo.
* O problema persistia porque:

  * A IA respondia em **texto livre**.
  * O **LangGraph não conseguia interpretar corretamente** qual era o próximo nó.
  * Pequenas variações de formato quebravam o fluxo.

---

### Solução proposta: uso de Tools

* A correção é feita criando uma **ferramenta de roteamento**:

  * `RoutingTool`.
* A ideia é:

  * **Forçar a IA a responder em um formato estruturado e válido**.
  * Eliminar respostas livres e imprevisíveis.

---

### Declaração da RoutingTool

* A ferramenta é apenas **declarada**, não implementada.
* Informações definidas:

  * **Nome**: `RoutingTool`
  * **Descrição**: selecionar o próximo estado.
* Uso de **Zod** para definir o esquema de entrada:

  * Um objeto com a propriedade `next`.
  * `next` é um enum com valores possíveis:

    * `FinancialSpecialist`
    * `SchedulingSpecialist`
    * `CommsSpecialist`
    * `End`
* Isso define, de forma explícita, **quais opções a IA pode escolher**.

---

### Binding da ferramenta à IA

* A ferramenta é vinculada dinamicamente ao modelo usando:

  * `AI.bindTools([RoutingTool])`
* É usado `toolChoice` para:

  * **Forçar a IA a usar obrigatoriamente a RoutingTool**.
* Com isso:

  * A IA não pode mais responder em texto livre.
  * Ela é obrigada a realizar uma **chamada de função**.

---

### Garantia de saída estruturada

* Ao chamar `AIWithTool.invoke(...)`:

  * A resposta vem com `toolCalls`.
* O próximo nó é extraído de:

  * `aiResponse.toolCalls[0].args.next`
* Não há mais:

  * Quebras de linha.
  * Texto extra.
  * Ambiguidade no formato.

---

### Integração com o grafo

* O Supervisor agora:

  * Retorna diretamente o valor de `nextNode` vindo da tool.
* Caso extremo:

  * Pode existir um fallback se nenhuma tool for chamada (embora isso não deva acontecer, pois a escolha é forçada).

---

### Comportamento inicial observado

* Sem contexto adicional:

  * A IA tende a escolher sempre o mesmo especialista.
  * Isso pode gerar **loops**, como chamar repetidamente o Financial Specialist.
* Isso não é um bug técnico:

  * É falta de **contexto semântico** para a IA decidir melhor.

---

### Adicionando contexto à decisão

* Ao passar entradas como:

  * “Quero ver minhas contas” → Financial Specialist.
  * “Quero ver minha agenda” → Scheduling Specialist.
  * “Quero mandar uma mensagem” → Comms Specialist.
  * “Não preciso de mais nada” → End.
* A IA passa a:

  * Tomar decisões coerentes.
  * Encerrar o fluxo corretamente quando necessário.

---

### Resultado alcançado

* O Supervisor agora:

  * Decide o próximo nó usando IA.
  * Sempre retorna um valor válido e estruturado.
* O roteamento deixa de quebrar o grafo.
* O sistema já funciona como um **orquestrador inteligente**.

---

### Limitações atuais

* A decisão ainda é:

  * “Burra”, pois não há histórico nem contexto acumulado.
* Os especialistas:

  * Ainda não executam ações reais.
  * Apenas retornam o controle ao Supervisor.

---

### Próximos passos anunciados

* Adicionar:

  * **Prompt inicial mais rico** para a IA.
  * **Histórico da conversa**.
* Fazer com que:

  * Os especialistas executem ações concretas.
  * A conversa flua de forma contínua.
* Evoluir para um **sistema multiagentes funcional de verdade**.
